<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Screen Capture</title>
    <style>
        body { font-family: sans-serif; margin: 20px; background-color: #f4f4f4; color: #333; }
        #videoContainer {
            margin-top: 20px;
            border: 1px solid #ccc;
            width: 80%;
            max-width: 640px;
            background-color: #000;
        }
        video { display: block; width: 100%; }
        button {
            padding: 10px 15px;
            font-size: 16px;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
        }
        button:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <h1>Screen Capture App</h1>
    <p>Click the button below to start capturing your screen. Video frames will be sent to the AI.</p>
    <button id="startCapture">Start Screen Capture</button>
    <div id="videoContainer">
        <video id="screenVideo" autoplay playsinline></video>
    </div>
    <canvas id="captureCanvas" style="display:none;"></canvas>

    <script>
        const videoElement = document.getElementById('screenVideo');
        const startButton = document.getElementById('startCapture');
        const captureCanvas = document.getElementById('captureCanvas');
        let videoStreamInterval;

        startButton.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getDisplayMedia({
                    video: {
                        cursor: "always"
                    },
                    audio: false
                });
                videoElement.srcObject = stream;

                videoElement.onloadedmetadata = () => {
                    const aspectRatio = videoElement.videoWidth / videoElement.videoHeight;
                    captureCanvas.width = 320; // Smaller dimension for sending
                    captureCanvas.height = Math.round(captureCanvas.width / aspectRatio);
                    console.log(`Canvas dimensions set to: ${captureCanvas.width}x${captureCanvas.height}`);
                };

                videoElement.onplay = () => {
                    console.log("Video playback started. Attempting to send frames.");
                    if (videoStreamInterval) clearInterval(videoStreamInterval);

                    videoStreamInterval = setInterval(() => {
                        if (window.aiSession && typeof window.aiSession.send === 'function') {
                            const ctx = captureCanvas.getContext('2d');
                            ctx.drawImage(videoElement, 0, 0, captureCanvas.width, captureCanvas.height);
                            const base64ImageData = captureCanvas.toDataURL('image/jpeg', 0.7).split(',')[1];

                            const payloadToSend = {
                                parts: [{
                                    inlineData: {
                                        mimeType: "image/jpeg",
                                        data: base64ImageData
                                    }
                                }]
                            };

                            window.aiSession.send(payloadToSend)
                                .then(() => {
                                    console.log("Sent video frame to AI.");
                                })
                                .catch(err => {
                                    console.error("Error sending video frame:", err);
                                    // Consider stopping interval on persistent errors
                                });
                        } else {
                            // console.debug("AI session not ready or send method not available.");
                        }
                    }, 1000); // Send frame every 1 second
                };

                stream.getVideoTracks()[0].addEventListener('ended', () => {
                    console.log('Screen capture ended');
                    if (videoStreamInterval) clearInterval(videoStreamInterval);
                    // Optionally, you might want to inform the AI session or close it
                    // if (window.aiSession) window.aiSession.close();
                });

            } catch (err) {
                console.error("Error starting screen capture: " + err);
                alert("Could not start screen capture. Please ensure you have granted permission and your browser supports this feature.");
            }
        });
    </script>
    <script type="module">
        import { GoogleGenAI, Modality } from 'https://esm.run/@google/genai';

        window.aiSession = null; // Expose session to global scope

        // IMPORTANT: Replace "GOOGLE_API_KEY" with your actual API key
        const ai = new GoogleGenAI({ apiKey: "GOOGLE_API_KEY" }); 
        const model = 'gemini-2.0-flash-live-001'; // Ensure this model supports live video input
        const config = { responseModalities: [Modality.TEXT] };

        async function main() {
          try {
            const session = await ai.live.connect({
              model: model,
              callbacks: {
                onopen: function () {
                  console.debug('AI session Opened');
                },
                onmessage: function (message) {
                  console.debug('AI Message:', message);
                  // Handle incoming messages from the AI if needed
                  if (message.text) {
                    console.log("AI Response Text:", message.text);
                  }
                },
                onerror: function (e) {
                  console.debug('AI Error:', e.message);
                },
                onclose: function (e) {
                  console.debug('AI Close:', e.reason);
                  window.aiSession = null; // Clear session on close
                  if (videoStreamInterval) clearInterval(videoStreamInterval); // Stop sending frames
                },
              },
              config: config,
            });

            window.aiSession = session;
            console.log("AI session started. Ready for video frames when screen capture begins.");

          } catch (error) {
            console.error("Failed to initialize AI session:", error);
            alert("Could not initialize AI session. Check console for details and ensure your API key and model are correct.");
          }
        }

        main().catch(console.error);
    </script>
</body>
</html> 